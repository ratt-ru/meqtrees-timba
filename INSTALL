        Installation instructions for MeqTree (Timba)

1. Prerequisites 

  Current version numbers given; not guaranteed to work with earlier versions.
  (Most of this can be found on lofar9/10 under /usr/local/src.)

  For the basic build:

    * Access to cvs.astron.nl. Read the LOFAR Build System document!

    * gcc-3.4.3

    * GNU toolset: automake 1.6.3, autoconf 2.53, libtool 1.5.2

    * A recent (post-library split, namespace casa) build of AIPS++.

    * Blitz++ 0.8

  For the Python meqbrowser (build/install in this order!)

    * Qt 3.3.2

    * Python 2.3.4

    * numarray-0.9 (Python package)

    * sip-4.0.1 (see http://www.riverbankcomputing.co.uk/pyqt/index.php)

    * PyQt-3.12

  For meqbrowser's Qwt visualization plug-ins:
  
    * PyQwt-4.1

  For meqbrowser's Hippo visualization plug-ins:

    * Boost-jam 3.1.10

    * Boost 1.31.0

    * Hippodraw 1.12
    
  
2. Installation notes for external packages

  Generally, we build everything from source, and keep it under /usr/local. Look
  on lofar9/10 for an example layout. Configuartion/build notes on specific
  packages:

  2.1. gcc-3.4

  The gcc-3.3 series is OK too, but I've noticed spurious crashes with some
  code, so 3.4.x is the recommended version.

  We configure it as follows:

  configure --prefix=/usr/local/gcc-3.4.3 
            --enable-threads=posix 
            --enable-version-specific-runtime-libs 
            --enable-languages=c,c++,f77
  make bootstrap && make install

  You may want to then set CC=/usr/local/gcc-3.4.3/bin/gcc and 
  CXX=/usr/local/gcc-3.4.3/bin/g++ in your environment, so that everything else
  is built with this compiler (this does matter for some of the packages!)

  2.2 GNU tools

  Configure with --prefix=/usr/local, and make sure that /usr/local/bin is first
  in your $PATH. Or just upgrade whatever version is in /usr.

  2.3. AIPS++ 

  As long as you've sourced aipsinit (i.e. your $AIPSPATH is set correctly), the
  LOFAR build system will figure everything else out. However, you may need to
  build AIPS++ with the same compiler as you use for this project. (Due to some
  STL library incompatibilities between gcc-3.3 and 3.4).

  2.4. Blitz++

  ./configure --prefix=/usr/local/blitz/gnu3
  make && make install

  Blitz is somewhat sensitive to compilers, hence you need to keep different
  version if you use other compilers, the strange install path (the LOFAR build
  system will look for it there). Build it with the same compiler as you use for 
  the project.
  
  The make install script of Blitz is slightly broken, you will need to copy an
  additional file over manually:
  
    # (over in the blitz++ source directory)
  $ cp -a /usr/local/src/blitz-0.8/blitz/gnu /usr/local/blitz/gnu3/include/blitz

  2.5. Qt 3.3.2

  ./configure -thread -enable-opengl -prefix /usr/local/qt-3.3.2
  make && make install

  2.6. Python 2.3.4

  ./configure --prefix=/usr/local
  make && make install

  After make install, set /usr/bin/python to link to /usr/local/bin/python2.3,
  and /usr/include/python2.3 to /usr/local/include/python2.3.

  2.7. numarray-0.9 (Python package)

  See README. Run "python setup.py install" using the python built above, it
  should figure out the rest.

  2.8. sip

  See README. You'll probably need to run:
  
    configure.py -l qt-mt CXX="$CXX" CC="$CC"
    make && make install
    
  2.9. PyQt

  See README. You'll probably need to run:
  
    python configure.py 
    make && make install
    
  2.9. PyQwt

  See README. You'll probably need to run:
  
    python configure.py 
    make && make install
    
  2.10. Boost-jam, Boost 
    
    See specific installation instructions for these packages. Install to
    /usr/local, and don't forget to enable boost-python.

  2.11. Hippodraw 

  ./configure --prefix=/usr/local --enable-sipbuild --enable-numarraybuild
  --with-boost-include=/usr/local/boost-1.31.0/include/boost-1_31
  --with-boost-lib=/usr/local/boost-1.31.0/lib/ --with-Qt-dir=/usr/local/qt-3.3.2
  --with-Qt-lib=qt-mt
  
  ...was the easy part. As of 1.12.2, they still have a broken configure script,
  so you now need to set up some stuff by hand. Go into the ./sip subdirectory
  of the Hippo source tree, and look at the INSTALL file there. Specifically,
  you need to make sure that sip/Makefile contains:

      SIP = /usr/local/bin/sip
      PYQT_SRCS = -I /usr/local/share/sip -I /usr/local/share/sip/qtcanvas
      
  and finally, find the lines that look like:

      sipsihippocmodule.h : $(SIP_SRCS) 
	      @echo creating built sources
	      $(SIP) -e -g -c . $(PYQT_SRCS) -I $(top_srcdir)/sip  \
	      -t Qt_3_3_0 -t WS_X11 $(top_srcdir)/sip/sihippo.sip
  
  and make sure it says "Qt_3_3_0" for Qt-3.3.x (better check versions.sip
  too, just like the INSTALL file in sip instructs you).
  
  Now, back in the base of the Hippo source tree:
  make && make install

3. Checking out and building MeqTree per se

  Assuming you have $CVSROOT set properly:

    :pserver:USERNAME@cvs.astron.nl:/cvs/cvsroot

  1. Start with 

    $ cvs login 
          # (persist until it logs you in)
    $ cvs co LOFAR/autoconf_share
    $ cvs co LOFAR/LCS/Common
    $ cvs co LOFAR/Timba

  2. Create a variants file for your machine. Use variants.lofar10 as a 
    starting point.

    $ cd LOFAR/autoconf_share
      # this is assuming you're not on lofar10 to begin with.
    $ cp variants.lofar10 variants.YOUR_HOST_NAME

    Now check the variants file to make sure the compiler specification (CXX),
    Qt and aips++ paths all match your system. (Have no fear, if they don't, 
    you'll learn about it soon enough anyway).

    Note the use of "CXX=ccache\ /path/to/g++" in the file. This assumes you
    have ccache installed (and you should, it makes rebuilds a helluva lot 
    faster.) If you don't, just give the direct path to the compiler instead.
    
  3. The LOFAR build environment kind of hinges on the LCS/Common directory.
    Even though we no longer use any code from it, it must still be configured
    for stuff to work. This is a one-time operation (hopefully, you'll do it
    once for each build variant, and never touch it again):

    $ cd ~/LOFAR/LCS/Common
    $ ./bootstrap
    $ mkdir -p build/gnu3_debug    # it may already be there...
    $ cd build/gnu3_debug
    $ ../../lofarconf

  4. Bootstrap the Timba build environment, create build directory, configure:

    $ cd ~/LOFAR/Timba
    $ ./bootstrap
  # (watch messages go by...)
    $ mkdir -p build/gnu3_debug    # it may already be there...
    $ cd build/gnu3_debug
    $ ../../lofarconf
  # (watch messages go by...)
    $

  5. Now, an evil but necessary kludge until Ger gets automake to submit to 
    our wishes:

    $ cd ~/LOFAR/Timba/OCTOPython/build/gnu3_debug/src
    $ ln -s octopython.la liboctopython.la

    (If you skip this step, PyApps will complain about a missing 
    liboctopython.la during the build.)

  6. Build!

    $ cd ~/LOFAR/Timba/build/gnu3_debug
    $ make 
  # (Go out to lunch)
    $

  6a. On lofar9/10, you may harness the awesome power of distcc and clustering, 
    to build at relativistic speeds on 20+ CPUs:

    $ mkdir ~/.distcc
  # copy over my distcc hosts file:
    $ cp ~oms/.distcc/hosts ~/.distcc
    $ export CCACHE_PREFIX=distcc    # this assumes bash, tcsh use setenv
    $ make -j40 
  # and hope it works...

  7. Installing the software.

    Assuming make was successful:

    $ cd ~/LOFAR/build/gnu3_debug
    $ make install

    This copies the built software and scripts into
    ~/LOFAR/installed/gnu3_debug. Handy for doing "snapshot"-style installs. 

  7a. Symlinking instead of installing

    A handy alternative is to set up a tree of symlinks directly into the
    source/build tree. Then, you never need to install, only edit/rebuild. I 
    recommend this approach if you're editing scripts, as it saves a lot of
    useless installs. 
    
    A tarball that unpacks into a tree of symlinks is provided in CVS. Try:

      $ cd ~/LOFAR/installed
      $ tar zxvf ../Timba/install-symlinked.tgz
    
    This creates and populates LOFAR/installed/symlinked. You should then do ln
    -s symlinked current, to use symlinked as the "current" install version.

    In the unlikely (but unfortunately known to happen...) even that the
    tarball  is out of date, you may check my home directory on lofar10 for a
    more up-to-date tree:
      (lofar10:/home/oms/LOFAR/installed/symlinked)

    You should be able to just copy my tree (since I use relative symlinks) and
    have everything work:

    $ slogin lofar10
    # (login)
    $ cd /home/oms/LOFAR/installed
    $ tar cvf ~/symlinks.tar symlinked.tar
    # (move the .tar file to your machine, and untar under your LOFAR/installed)

    Alternatively, you can copy them over directly, if you have access to my
    home directory locally. E.g., working on lofar9, you could do:

    $ cd ~/LOFAR/installed
    $ cp -a /net/lofar10/home/oms/LOFAR/installed/symlinked .

  8. Setting up include paths

    For Python, you need to set the $PYTHONPATH environment variable to

        $HOME/LOFAR/installed/current/libexec/python

    For Glish, just copy (or merge) LOFAR/Timba/.glishrc into your ~/.glishrc.

    Note that this assumes that scripts and binaries may be found under
    ~/LOFAR/installed/current. 'current' should be set up as a symlink to
    whatever installation variant you actually want to use, i.e.,
    LOFAR/installed/gnu3_debug, or LOFAR/installed/symlinked.

  9. Some "simple" test trees

    To start the MEQ browser, run 
    LOFAR/installed/current/libexec/python/meqbrowser.py
    (or LOFAR/Timba/PyApps/src/meqbrowser.py, whichever's handier)

    In theory, you can just run leave the browser running permanently, as it
    connects/disconnects to the kernel automatically.

    To run a very simple test tree, go to 

    $ cd ~/LOFAR/Timba/MeqServer/build/gnu3_debug
    $ glish -l ../../test/solver_test.g
    # and then at the glish prompt:
    - solver_test(0)
    # watch sparks fly, and use the browser to examine the tree
    # (if you don't see a tree, try clicking the refresh button at the top of the
    # tree list).

  9a. When things go wrong(TM)

    The kernel is run in a process called 'meqserver'. This process will usually
    exit when you exit your glish session, but for reasons that are not yet 
    entirely clear, it may sometimes stay running in the background. Then, next
    time 'round you may end up with two running meqservers, at which point
    things get a little confusing for the browser. Someday I will resolve this
    cleanly, but in the meantime,

    $ killall -9 meqserver

    is a useful incantation to know.

  10. meqsolve.g

    Meqsolver.g solves for two sources in a Haystack simulated data set. To run
    meqsolve.g, you need to get a test measurement set. You can get one from
    the Water Hole, e.g. try this path: 

    lofar10:/usr/local/Timba/WH/ms/Haystack-Sim/2PointSourceNoiseless/0128_vis_ninterp.MS

    and copy it some place you won't lose it... Now, set up a few more symlinks:

    $ cd ~/LOFAR/Timba/MeqServer/build/gnu3_debug
    $ ln -s ../../test/*.g .
    $ ln -s src/meqserver .
    $ ln -s path/to/your/copy/of/test/measurement/set test.ms

    Now, you may run meqsolve.g. The very first time you run it for a particular
    MS, you need to supply the '-filluvw' argument to fill the UVW tables.
    Subsequent runs over the same MS do not need this flag (it won't break
    things afterwards, but it's slow and useless to repeat the process.)

    $ glish -l meqsolve.g -filluvw

    Everything else is controlled by editing meqsolve.g itself...
    
  
